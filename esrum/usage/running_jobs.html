

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Running jobs using Slurm &#8212; Esrum Cluster  documentation</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/playback.css" />
    
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/js/libgif.js"></script>
    <script src="../_static/bizstyle.js"></script>
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Running batch jobs" href="batch_jobs.html" />
    <link rel="prev" title="The filesystem" href="filesystem.html" />
    <script defer src="../_static/js/playback.js"></script>

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="batch_jobs.html" title="Running batch jobs"
             accesskey="N">next</a></li>
        <li class="right" >
          <a href="filesystem.html" title="The filesystem"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Esrum Cluster  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" accesskey="U">Using the cluster</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Running jobs using Slurm</a><ul>
<li><a class="reference internal" href="#running-commands-using-slurm">Running commands using Slurm</a></li>
<li><a class="reference internal" href="#running-an-interactive-shell">Running an interactive shell</a></li>
<li><a class="reference internal" href="#reserving-resources-for-your-jobs">Reserving resources for your jobs</a></li>
<li><a class="reference internal" href="#reserving-gpus">Reserving GPUs</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="filesystem.html"
                        title="previous chapter">The filesystem</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="batch_jobs.html"
                        title="next chapter">Running batch jobs</a></p>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="running-jobs-using-slurm">
<span id="page-running"></span><h1>Running jobs using Slurm<a class="headerlink" href="#running-jobs-using-slurm" title="Permalink to this headline">¶</a></h1>
<p>The Esrum cluster makes use of the <a class="reference external" href="https://slurm.schedmd.com/overview.html">Slurm</a> job management system in order
to queue and distribute jobs on the compute and GPU nodes. This section
describes how to how to run basic jobs, how to start an interactive
shell on a compute node, and how to reserve the needed resources for
your tasks.</p>
<p>It is strongly recommended that you run <a class="reference external" href="https://github.com/tmux/tmux/wiki">tmux</a> or a similar tool before
starting tasks using <code class="docutils literal notranslate"><span class="pre">srun</span></code>, in order to ensure that your work is not
interrupted if you lose connection to the server or need to turn off
your PC. See the <a class="reference internal" href="../tips_and_tricks/tmux.html#tmux-page"><span class="std std-ref">Persistent sessions with tmux</span></a> page for a short tutorial.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Resource intensive jobs <em>must</em> be run using Slurm. Your tasks <em>will</em>
be terminated without prior warning if you fail to do so, in order to
prevent any impact on other users of the cluster.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Show consideration towards other users of the cluster. If you need to
run very intensive jobs then please <a class="reference internal" href="../contact.html#page-contact"><span class="std std-ref">Contact</span></a> Phenomics
first so that we can ensure that the cluster will still be usable by
other users while your jobs are running. Failure to do so may result
in your jobs being terminated without prior warning.</p>
</div>
<div class="section" id="running-commands-using-slurm">
<h2>Running commands using Slurm<a class="headerlink" href="#running-commands-using-slurm" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">srun</span></code> command is used to queue and execute commands on the
compute nodes, and for most part it should feel no different than
running a command on the head node. Simply prefix your command with
<code class="docutils literal notranslate"><span class="pre">srun</span></code> and the queuing system takes care of running it on the first
available compute node:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">srun gzip chr20.fasta</span>
</pre></div>
</div>
<img alt="../_images/srun_minimal.gif" class="gif" src="../_images/srun_minimal.gif" />
<p>Except for the <code class="docutils literal notranslate"><span class="pre">srun</span></code> prefix, this is exactly as if you ran the
<code class="docutils literal notranslate"><span class="pre">gzip</span></code> command on the head node. However, if you need to pipe output
to a file or to another command, then you <em>must</em> wrap your commands in a
bash (or similar) script. The script can then be run using <code class="docutils literal notranslate"><span class="pre">srun</span></code>:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">srun bash my_script.sh</span>
</pre></div>
</div>
<img alt="../_images/srun_wrapped.gif" class="gif" src="../_images/srun_wrapped.gif" />
<p>For tips to make your bash scripts more robust, see the <a class="reference internal" href="../tips_and_tricks/safer_bash_scripts.html#page-bash"><span class="std std-ref">Writing reliable bash scripts</span></a>
page.</p>
<p>By default task are allocated one CPU and 15 GB of RAM. If you need to
use additional resources, then see <a class="reference internal" href="#reserving-resources-for-your-jobs">Reserving resources for your jobs</a>
and <a class="reference internal" href="#reserving-gpus">Reserving GPUs</a> below.</p>
</div>
<div class="section" id="running-an-interactive-shell">
<h2>Running an interactive shell<a class="headerlink" href="#running-an-interactive-shell" title="Permalink to this headline">¶</a></h2>
<p>If you need to run an interactive process, for example if you need to
use an interactive R shell to process a large dataset, or if you just
need to experiment with running an computationally heavy process, then
you can start a shell on one of the compute nodes as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">[abc123@esrumhead01fl ~] $</span> srun --pty -- /bin/bash
<span class="gp">[abc123@esrumcmpn07fl ~] $</span>
</pre></div>
</div>
<p>Note that the hostname displayed changes from <code class="docutils literal notranslate"><span class="pre">esrumhead01fl</span></code> to
<code class="docutils literal notranslate"><span class="pre">esrumcmpn07fl</span></code>, where <code class="docutils literal notranslate"><span class="pre">esrumcmpn07fl</span></code> is one of the eight Esrum
compute nodes.</p>
<p>You can now run interactive jobs, for example running an R shell, or
test computationally expensive tools or scripts. Once you are done, exit
the interactive shell by using the <code class="docutils literal notranslate"><span class="pre">exit</span></code> command or pressing
<code class="docutils literal notranslate"><span class="pre">Ctrl+D</span></code>.</p>
<p>Be sure to exit the interactive session once you are done working, so
that the resources reserved for your shell is made available to other
users!</p>
</div>
<div class="section" id="reserving-resources-for-your-jobs">
<h2>Reserving resources for your jobs<a class="headerlink" href="#reserving-resources-for-your-jobs" title="Permalink to this headline">¶</a></h2>
<p>By default a <code class="docutils literal notranslate"><span class="pre">srun</span></code> will reserve 1 CPU (2 threads) and 8 GB of ram per
CPU. Should your job require more CPUs or RAM, then you can request CPUs
using the <code class="docutils literal notranslate"><span class="pre">-c</span></code> or <code class="docutils literal notranslate"><span class="pre">--cpus-per-task</span></code> options, and request RAM using
the <code class="docutils literal notranslate"><span class="pre">--mem</span></code> or <code class="docutils literal notranslate"><span class="pre">--mem-per-cpu</span></code> options. Values given to <code class="docutils literal notranslate"><span class="pre">--mem</span></code>
are assumed to be in megabytes by default, but this may be overridden by
using an explicit unit (M for megabyte, G for gigabyte, T for terabyte):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span> Run a task with <span class="m">8</span> CPUs and <span class="m">64</span> gigabytes of memory
<span class="go">srun -c 8 --mem 64G -- my-command</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you</p>
</div>
</div>
<div class="section" id="reserving-gpus">
<h2>Reserving GPUs<a class="headerlink" href="#reserving-gpus" title="Permalink to this headline">¶</a></h2>
<p>To reserve GPU resources, you need to select the GPU queue and
(optionally) specify the number of Nvidia A100 GPUs (1 or 2) needed. The
following command queues command <code class="docutils literal notranslate"><span class="pre">${COMMAND}</span></code> and requests a single
A100 GPU:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">srun --partition=gpuqueue --gres=gpu:a100:1 -- ${COMMAND}</span>
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="batch_jobs.html" title="Running batch jobs"
             >next</a></li>
        <li class="right" >
          <a href="filesystem.html" title="The filesystem"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">Esrum Cluster  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="index.html" >Using the cluster</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2023, CBMR Phenomics.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.4.
    </div>
  </body>
</html>